{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbb83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "# Configure Spark to use a local master\n",
    "launcher.master = \"local\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a680a7",
   "metadata": {},
   "source": [
    "## 데이터 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebe24dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"json\").load(\"2015-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeeb89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678f0879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6a0be",
   "metadata": {},
   "source": [
    "## 5.1 스키마\n",
    "### 스키마는 Dataframe의 컬럼명과 데이터 타입을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba02e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructField, StructType, StringType, LongType}\n",
       "import org.apache.spark.sql.types.Metadata\n",
       "myManualSchema: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true), StructField(ORIGIN_COUNTRY_NAME,StringType,true), StructField(count,LongType,false))\n",
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructField, StructType, StringType, LongType}\n",
    "import org.apache.spark.sql.types.Metadata\n",
    "\n",
    "val myManualSchema = StructType(Array(\n",
    "  StructField(\"DEST_COUNTRY_NAME\", StringType, true),\n",
    "  StructField(\"ORIGIN_COUNTRY_NAME\", StringType, true),\n",
    "  StructField(\"count\", LongType, false,\n",
    "    Metadata.fromJson(\"{\\\"hello\\\":\\\"world\\\"}\"))\n",
    "))\n",
    "\n",
    "val df = spark.read.format(\"json\").schema(myManualSchema)\n",
    "  .load(\"2015-summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895df1b",
   "metadata": {},
   "source": [
    "## 5.2 컬럼과 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2280ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, column}\n",
       "res1: org.apache.spark.sql.Column = someColumnName\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, column}\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4606f",
   "metadata": {},
   "source": [
    "### 명시적 컬럼 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a46c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.sql.Column = count\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.col(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6397243",
   "metadata": {},
   "source": [
    "### 표현식으로 컬럼 표현\n",
    "\n",
    "#### 컬럼은 표현식의 일부 기능을 제공한다\n",
    "#### col() 함수를 호출해 컬럼에 트랜스포메이션 수행 시, 컬럼 참조를 이용해야 한다\n",
    "#### 컬럼과 컬럼의 트랜스포메이션은 파싱된 표현식과 동일한 논리적 실행계획으로 컴파일된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca459d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: org.apache.spark.sql.Column = ((((someCol + 5) * 200) - 6) < otherCol)\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((col(\"someCol\") + 5) * 200) - 6) < col(\"otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32de5de",
   "metadata": {},
   "source": [
    "## DataFrame 컬럼에 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389dcdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[String] = Array(DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count)\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0de31b",
   "metadata": {},
   "source": [
    "## 레코드와 Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "143da11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: org.apache.spark.sql.Row = [United States,Romania,15]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a832dca",
   "metadata": {},
   "source": [
    "## 로우 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c589d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "myRow: org.apache.spark.sql.Row = [Hello,null,1,false]\n",
       "res10: Int = 1\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "val myRow = Row(\"Hello\", null, 1, false)\n",
    "\n",
    "myRow(0) // type Any\n",
    "myRow(0).asInstanceOf[String] // String\n",
    "myRow.getString(0) // String\n",
    "myRow.getInt(2) // Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d984f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTabe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb908000",
   "metadata": {},
   "source": [
    "## select와 selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71f8c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0da59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79ecd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{expr, col, column}\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{expr, col, column}\n",
    "df.select(\n",
    "    df.col(\"DEST_COUNTRY_NAME\"),\n",
    "    col(\"DEST_COUNTRY_NAME\"),\n",
    "    column(\"DEST_COUNTRY_NAME\"),\n",
    "    'DEST_COUNTRY_NAME,\n",
    "    $\"DEST_COUNTRY_NAME\",\n",
    "    expr(\"DEST_COUNTRY_NAME\"))\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d154c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617db46",
   "metadata": {},
   "source": [
    "#### alias로 컬럼명을 변경 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "278d38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME as destination\").alias(\"DEST_COUNTRY_NAME\"))\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835b505",
   "metadata": {},
   "source": [
    "#### select와 expr를 같이 쓰는 패턴을 자주 사용하는데, selectExpr로 두 기능을 합칠 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09a6df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|newColumnName|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME as newColumnName\", \"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "021a4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/**\n",
    "목적지가 출발지와 같은지를 파악하는 withinCountry 컬럼을 추가\n",
    "*/\n",
    "\n",
    "df.selectExpr(\n",
    "    \"*\", // include all original columns\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa62093",
   "metadata": {},
   "source": [
    "## 컬럼 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "252625a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f9d1aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/**\n",
    "출발지와 도착지가 같은지 여부를 불리언 타입으로 표현\n",
    "*/\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\"))\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfb0ff",
   "metadata": {},
   "source": [
    "## 컬럼명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d99af9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res27: Array[String] = Array(dest, ORIGIN_COUNTRY_NAME, count)\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "wthColumnRenamed 명령어로 첫번째 인수의 컬럼명을 두번째 인수의 문자열로 변경\n",
    "*/\n",
    "\n",
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb518f",
   "metadata": {},
   "source": [
    "## 컬럼 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83cd88c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: Array[String] = Array(DEST_COUNTRY_NAME, count)\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd0dbc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res33: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true), StructField(ORIGIN_COUNTRY_NAME,StringType,true), StructField(count,LongType,true), StructField(count2,StringType,true))\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"count2\", col(\"count\").cast(\"string\")).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ace972",
   "metadata": {},
   "source": [
    "## 로우 필터링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1669db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"count\") < 2).show(2)\n",
    "df.where(\"count < 2\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f2cd497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/**\n",
    "여러 필터를 동시에 적용할 수도 있다\n",
    "그러나 필터의 순서와 상관 없이 동시에 모든 필터링 작업을 수행하므로 주의\n",
    "*/\n",
    "\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") =!= \"Croatia\")\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917025a7",
   "metadata": {},
   "source": [
    "## 고유한 로우 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3efcd4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: Long = 256\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c20f93cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res38: Long = 125\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae861b",
   "metadata": {},
   "source": [
    "## 무작위 샘플 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d47e0c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seed: Int = 5\n",
       "withReplacement: Boolean = false\n",
       "fraction: Double = 0.5\n",
       "res39: Long = 138\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 5\n",
    "val withReplacement = false /**복원 비복원 추출 여부*/\n",
    "val fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d02b66",
   "metadata": {},
   "source": [
    "## 임의 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d414578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataFrames: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field], [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field])\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "임의 분할은 원본 데이터프레임을 임의의 크기로 분할할 시 유용하게 사용된다\n",
    "머신러닝 알고리즘에서 사용할 학습셋, 검증셋,테스트셋을 만들 때 유용하다\n",
    "*/\n",
    "val dataFrames = df.randomSplit(Array(0.25, 0.75), seed)\n",
    "print(dataFrames(0).count() > dataFrames(1).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609252d",
   "metadata": {},
   "source": [
    "## 로우 합치기와 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b910a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true), StructField(ORIGIN_COUNTRY_NAME,StringType,true), StructField(count,LongType,true))\n",
       "newRows: Seq[org.apache.spark.sql.Row] = List([New Country,Other Country,5], [New Country 2,Other Country 3,1])\n",
       "parallelizedRows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = ParallelCollectionRDD[221] at parallelize at <console>:46\n",
       "newDF: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "DataFrame은 불변성을 가지기 때문에, 원본 데이터 프레임에 로우를 추가하는 것은 불가능하다\n",
    "\n",
    "새로운 데이터프레임과 통합하는 것은 가능하며, 동일한 스키마와 컬럼 수를 가져야 한다\n",
    "*/\n",
    "\n",
    "import org.apache.spark.sql.Row\n",
    "val schema = df.schema\n",
    "val newRows = Seq(\n",
    "  Row(\"New Country\", \"Other Country\", 5L),\n",
    "  Row(\"New Country 2\", \"Other Country 3\", 1L)\n",
    ")\n",
    "val parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "val newDF = spark.createDataFrame(parallelizedRows, schema)\n",
    "df.union(newDF)\n",
    "  .where(\"count = 1\")\n",
    "  .where($\"ORIGIN_COUNTRY_NAME\" =!= \"United States\")\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fed78",
   "metadata": {},
   "source": [
    "## 로우 정렬하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b83f5696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(5)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a84898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Moldova|      United States|    1|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{desc, asc}\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{desc, asc}\n",
    "df.orderBy(expr(\"count desc\")).show(2)\n",
    "df.orderBy(desc(\"count\"), asc(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f8bab",
   "metadata": {},
   "source": [
    "## repartition과 coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b559bc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res55: Int = 1\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions // 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5009cf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res64: Int = 3\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "repartition 메서드 호출시, 무조건 전체 데이터를 셔플한다\n",
    "향후 사용할 파티션 수가 현재 파티션 수보다 많거나 컬럼을 기준으로 파티션을 만드는 경우에만 사용\n",
    "*/\n",
    "df.repartition(3).rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91f5013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res65: Int = 200\n"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "특정 칼럼으로 자주 필터링을 한다면 자주 필터링되는 컬럼을 기준으로 파티션을 재분배 하는 것이 좋다\n",
    "*/\n",
    "df.repartition(col(\"DEST_COUNTRY_NAME\")).rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33ea4496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res66: Int = 5\n"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "선택적으로 파티션 수 지정 가능\n",
    "*/\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\")).rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce22f88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res67: Int = 2\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "coalesce는 전체 데이터를 셔플하지 않고 파티션을 병합하는 경우에 사용한다\n",
    "파티션 수를 줄이려면 셔플이 일어나는 repartition 대신 coalesce를 사용\n",
    "*/\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\")).coalesce(2).rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb959f5",
   "metadata": {},
   "source": [
    "## 드라이버로 로우 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ed2e691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collectDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n",
       "res69: Array[org.apache.spark.sql.Row] = Array([United States,Romania,15], [United States,Croatia,1], [United States,Ireland,344], [Egypt,United States,15], [United States,India,62])\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "스파크는 드라이버에서 클러스터 상태 정보를 유지한다\n",
    "로컬 환경에서 데이터를 다룬다면 드라이버르 데이터를 수집해야 한다\n",
    "*/\n",
    "\n",
    "val collectDF = df.limit(10)\n",
    "collectDF.take(5) // take works with an Integer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16c7ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collectDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b71ae988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collectDF.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de7d50e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res72: Array[org.apache.spark.sql.Row] = Array([United States,Romania,15], [United States,Croatia,1], [United States,Ireland,344], [Egypt,United States,15], [United States,India,62], [United States,Singapore,1], [United States,Grenada,62], [Costa Rica,United States,588], [Senegal,United States,40], [Moldova,United States,1])\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95e31cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res73: java.util.Iterator[org.apache.spark.sql.Row] = IteratorWrapper(<iterator>)\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "전체 데이터셋에 대한 반복 처리를 위해서는 toLocalIterator 메서드로 반복자의 방식으로 모든 파티션의 데이터를 드라이버로 전달\\\n",
    "\n",
    "데이터셋의 파티션을 차례대로 반복 처리할 수 있다.\n",
    "*/\n",
    "collectDF.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635995c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
