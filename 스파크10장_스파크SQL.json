{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538725457536_-91367199","id":"20181005-074417_1840856160","dateCreated":"2018-10-05T07:44:17+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2844"},{"title":"Paragraph insert revised","text":"%sh\n# For prevent crash with other note's execution,\n# I recommend to restart spark interpreter.\n# ?? ?? ??? ??? ???? ?? ???? ??, ?? ??? ?? spark interpreter ????? ?? ?????.\n\ncurl -X PUT http://localhost:8080/api/interpreter/setting/restart/spark","user":"anonymous","dateUpdated":"2021-07-11T00:59:08+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538725457548_-3362789","id":"20181005-074417_1351470456","dateCreated":"2018-10-05T07:44:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2845","dateFinished":"2021-07-11T00:59:11+0000","dateStarted":"2021-07-11T00:59:08+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r100  3988  100  3988    0     0   1416      0  0:00:02  0:00:02 --:--:--  1416\r100  3988  100  3988    0     0   1416      0  0:00:02  0:00:02 --:--:--  1416\n{\"status\":\"OK\",\"message\":\"\",\"body\":{\"id\":\"spark\",\"name\":\"spark\",\"group\":\"spark\",\"properties\":{\"zeppelin.spark.concurrentSQL\":{\"name\":\"zeppelin.spark.concurrentSQL\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.R.knitr\":{\"name\":\"zeppelin.R.knitr\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.R.cmd\":{\"name\":\"zeppelin.R.cmd\",\"value\":\"R\",\"type\":\"string\"},\"zeppelin.R.image.width\":{\"name\":\"zeppelin.R.image.width\",\"value\":\"100%\",\"type\":\"number\"},\"zeppelin.spark.importImplicit\":{\"name\":\"zeppelin.spark.importImplicit\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.dep.additionalRemoteRepository\":{\"name\":\"zeppelin.dep.additionalRemoteRepository\",\"value\":\"spark-packages,http://dl.bintray.com/spark-packages/maven,false;\",\"type\":\"textarea\"},\"zeppelin.dep.localrepo\":{\"name\":\"zeppelin.dep.localrepo\",\"value\":\"local-repo\",\"type\":\"string\"},\"zeppelin.spark.sql.stacktrace\":{\"name\":\"zeppelin.spark.sql.stacktrace\",\"value\":false,\"type\":\"checkbox\"},\"zeppelin.spark.useHiveContext\":{\"name\":\"zeppelin.spark.useHiveContext\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.printREPLOutput\":{\"name\":\"zeppelin.spark.printREPLOutput\",\"value\":true,\"type\":\"checkbox\"},\"spark.cores.max\":{\"name\":\"spark.cores.max\",\"value\":\"3\",\"type\":\"number\"},\"spark.executor.memory\":{\"name\":\"spark.executor.memory\",\"value\":\"2g\",\"type\":\"string\"},\"zeppelin.spark.sql.interpolation\":{\"name\":\"zeppelin.spark.sql.interpolation\",\"value\":false,\"type\":\"checkbox\"},\"spark.driver.memory\":{\"name\":\"spark.driver.memory\",\"value\":\"2g\",\"type\":\"textarea\"},\"spark.app.name\":{\"name\":\"spark.app.name\",\"value\":\"Zeppelin\",\"type\":\"string\"},\"zeppelin.spark.maxResult\":{\"name\":\"zeppelin.spark.maxResult\",\"value\":\"1000\",\"type\":\"number\"},\"master\":{\"name\":\"master\",\"value\":\"local[*]\",\"type\":\"string\"},\"zeppelin.pyspark.python\":{\"name\":\"zeppelin.pyspark.python\",\"value\":\"python\",\"type\":\"string\"},\"args\":{\"name\":\"args\",\"value\":\"\",\"type\":\"textarea\"},\"zeppelin.spark.enableSupportedVersionCheck\":{\"name\":\"zeppelin.spark.enableSupportedVersionCheck\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.useNew\":{\"name\":\"zeppelin.spark.useNew\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.pyspark.useIPython\":{\"name\":\"zeppelin.pyspark.useIPython\",\"value\":true,\"type\":\"checkbox\"},\"zeppelin.spark.uiWebUrl\":{\"name\":\"zeppelin.spark.uiWebUrl\",\"value\":\"\",\"type\":\"string\"},\"zeppelin.R.render.options\":{\"name\":\"zeppelin.R.render.options\",\"value\":\"out.format \\u003d \\u0027html\\u0027, comment \\u003d NA, echo \\u003d FALSE, results \\u003d \\u0027asis\\u0027, message \\u003d F, warning \\u003d F, fig.retina \\u003d 2\",\"type\":\"textarea\"},\"spark.jars\":{\"name\":\"spark.jars\",\"value\":\"/zeppelin/lib/sqlite-jdbc-3.23.1.jar\",\"type\":\"textarea\"}},\"status\":\"READY\",\"interpreterGroup\":[{\"name\":\"spark\",\"class\":\"org.apache.zeppelin.spark.SparkInterpreter\",\"defaultInterpreter\":true,\"editor\":{\"language\":\"scala\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"sql\",\"class\":\"org.apache.zeppelin.spark.SparkSqlInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"sql\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"dep\",\"class\":\"org.apache.zeppelin.spark.DepInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"scala\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"pyspark\",\"class\":\"org.apache.zeppelin.spark.PySparkInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"python\",\"editOnDblClick\":false,\"completionKey\":\"TAB\",\"completionSupport\":true}},{\"name\":\"ipyspark\",\"class\":\"org.apache.zeppelin.spark.IPySparkInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"python\",\"editOnDblClick\":false,\"completionSupport\":true}},{\"name\":\"r\",\"class\":\"org.apache.zeppelin.spark.SparkRInterpreter\",\"defaultInterpreter\":false,\"editor\":{\"language\":\"r\",\"editOnDblClick\":false,\"completionSupport\":false}}],\"dependencies\":[],\"option\":{\"remote\":true,\"port\":-1,\"perNote\":\"shared\",\"perUser\":\"shared\",\"isExistingProcess\":false,\"setPermission\":false,\"owners\":[],\"isUserImpersonate\":false}}}"}]}},{"title":"Paragraph insert revised","text":"%sql\n\n-- 테이블 생성\n-- 중요한 핵심: using 구문 필요. using은 포맷을 명시적으로 지정하지 않는다는 의미며 하이브 호환 테이블을 생성한다는 의미다. 안쓰면 스파크는 기본적으로 하이브 serde 설정을 사용해 성능 저하를 야기\nCREATE TABLE flights (\n  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\nUSING JSON OPTIONS (path '/data/flight-data/json/2015-summary.json')\n\n\n-- 테이블 생성 시 코멘트 작성 방법\nCREATE TABLE flights_csv (\n  DEST_COUNTRY_NAME STRING,\n  ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\n  count LONG)\nUSING csv OPTIONS (header true, path '/data/flight-data/csv/2015-summary.csv')\n\n\n-- 서브쿼리 가능 (위 쿼리 결과를 이용해 테이블 생성) #### 287page 오타\nCREATE TABLE flights_from_select USING parquet AS SELECT * FROM flights\n\n\n-- 지정한 테이블이 없다면 테이블을 생성하도록 함.\nCREATE TABLE IF NOT EXISTS flights_from_select\n  AS SELECT * FROM flights\n\n\n-- 파티셔닝된 데이터셋을 저장해 데이터 레이아웃을 제어\n\nCREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\nAS SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 5\n\n\n-- 외부 테이블 생성. 외부 테이블이란: 외부의 있는 데이터 파일을 불러서 그 껍데기 테이블에 데이터를 넣는 것\n\nCREATE EXTERNAL TABLE hive_flights (\n  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/data/flight-data-hive/'\n\n\n-- 외부 테이블 생성 시 select 쿼리 결과를 이용해 생성\n\nCREATE EXTERNAL TABLE hive_flights_2\nROW FORMAT DELIMITED FIELDS TERMINATED BY ','\nLOCATION '/data/flight-data-hive/' AS SELECT * FROM flights\n\n\n-- 테이블에 데이터 삽입\n\nINSERT INTO flights_from_select\n  SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 20\n\n\n-- 특정 파티션 테이블에 데이터 삽입\nINSERT INTO partitioned_flights\n  PARTITION (DEST_COUNTRY_NAME=\"UNITED STATES\")\n  SELECT count, ORIGIN_COUNTRY_NAME FROM flights\n  WHERE DEST_COUNTRY_NAME='UNITED STATES' LIMIT 12\n\n\n-- 테이블 메타 데이터 (추가적 코멘트) 확인\nDESCRIBE TABLE flights_csv\n\n\n-- 테이블 스키마 정보 확인\n\nSHOW PARTITIONS partitioned_flights\n\n\n-- 테이블과 관련된 캐싱된 항목들을 갱신해 최신 메타데이터 읽는 것 보장하는 작업\n\nREFRESH table partitioned_flights\n\n\n-- 카탈로그에서 관리하는 테이블의 파티션 정보를 새로 고치는 작업(갱신)\n\nMSCK REPAIR TABLE partitioned_flights\n\n\n-- 테이블 제거(이때 테이블 내 데이터 제거됨)\n\nDROP TABLE flights_csv;\n\n\n-- 존재하는 테이블일 경우 제거 (위처럼 제거했는데 만약 존재하지 않는 테이블이라면 오류가 발생하기 때문)\n\nDROP TABLE IF EXISTS flights_csv;\n\n\n-- 외부테이블을 제거하면? 외부 원본 데이터는 사제되지 않지만, 테이블 자체는 삭제된다.\n\n\n-- 테이블 캐시\nCACHE TABLE flights\n\n\n-- 캐시한 테이블 제거\n\nUNCACHE TABLE FLIGHTS\n\n\n-- 뷰 생성\n\nCREATE VIEW just_usa_view AS\n  SELECT * FROM flights WHERE dest_country_name = 'United States'\n\n\n-- 테이블처럼 DB에 등록되지 않고 현재 세션에서만 사용할 수 있도록 임시 뷰로 생성\n\nCREATE TEMP VIEW just_usa_view_temp AS\n  SELECT * FROM flights WHERE dest_country_name = 'United States'\n\n\n-- 전역적 임시 뷰 생성. 세션 내에서 사용할 수 있으며 DB 상관없이 전역적으로 사용이 가능한 뷰\n\nCREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n  SELECT * FROM flights WHERE dest_country_name = 'United States'\n\n\n-- 테이블 확인\nSHOW TABLES\n\n\n-- 생성된 뷰 덮어쓰기\n\nCREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n  SELECT * FROM flights WHERE dest_country_name = 'United States'\n\n\n-- 뷰 삭제: 뷰는 어떤 데이터도 제거되지 않으며 뷰 정의만 제거됨\n\nDROP VIEW IF EXISTS just_usa_view;\n\n\n-- 데이터 베이스 확인\n\nSHOW DATABASES\n\n\n-- 데이터 베이스 생성\n\nCREATE DATABASE some_db\n\n\n-- 데이터베이스 사용\n\nUSE some_db\n\n\n\n\n-- 다른 데이터베이스 테이블에 쿼리 수행하는 방법\n\nSELECT * FROM default.flights\n\n\n-- 현재사용하는 DB 확인\n\nSELECT current_database()\n\n\n-- 기본 데이터베이스로 돌아가기\n\nUSE default;\n\n\n-- 만약 some_db라는 DB가 존재한다면 삭제\n\nDROP DATABASE IF EXISTS some_db;\n\n\n\n\n\n-- Select 표현식의 구조 ----------\n\nSELECT [ALL|DISTINCT] named_expression[, named_expression, ...]\n    FROM relation[, relation, ...]\n    [lateral_view[, lateral_view, ...]]\n    [WHERE boolean_expression]\n    [aggregation [HAVING boolean_expression]]\n    [ORDER BY sort_expressions]\n    [CLUSTER BY expressions]\n    [DISTRIBUTE BY expressions]\n    [SORT BY sort_expressions]\n    [WINDOW named_window[, WINDOW named_window, ...]]\n    [LIMIT num_rows]\n\nnamed_expression:\n    : expression [AS alias]\n\nrelation:\n    | join_relation\n    | (table_name|query|relation) [sample] [AS alias]\n    : VALUES (expressions)[, (expressions), ...]\n          [AS (column_name[, column_name, ...])]\n\nexpressions:\n    : expression[, expression, ...]\n\nsort_expressions:\n    : expression [ASC|DESC][, expression [ASC|DESC], ...]\n\n\n\n\n-- Case When Then 구문 ----------\n\nSELECT\n  CASE WHEN DEST_COUNTRY_NAME = 'UNITED STATES' THEN 1\n       WHEN DEST_COUNTRY_NAME = 'Egypt' THEN 0\n       ELSE -1 END\nFROM partitioned_flights\n\n\n\n\n\n-- 구조체 생성 ----------\n\nCREATE VIEW IF NOT EXISTS nested_data AS\n  SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\n\n\n-- 구조체 조회 ----------\n\nSELECT * FROM nested_data\n\n\n-- 구조체 개별 칼럼 조회 ----------\n\nSELECT country.DEST_COUNTRY_NAME, count FROM nested_data\n\n\n-- 구조체의 모든 개별 칼럼들을 조회 ----------\n\nSELECT country.*, count FROM nested_data\n\n\n\n\n-- 리스트 조회 ----------: 값의 리스트 생성:collect_list / list함수나 중복값이 없는 배열 생성:collect_set\n\nSELECT DEST_COUNTRY_NAME as new_name, collect_list(count) as flight_counts,\n  collect_set(ORIGIN_COUNTRY_NAME) as origin_set\nFROM flights GROUP BY DEST_COUNTRY_NAME\n\n\n-- 칼럼에 직접 배열 생성 ----------\n\nSELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\n\n\n-- 리스트 특정 위치 데이터 로드 ----------\n\nSELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\nFROM flights GROUP BY DEST_COUNTRY_NAME\n\n\n-- 신규 뷰 생성(아래 구문 위함) ----------\n\nCREATE OR REPLACE TEMP VIEW flights_agg AS\n  SELECT DEST_COUNTRY_NAME, collect_list(count) as collected_counts\n  FROM flights GROUP BY DEST_COUNTRY_NAME\n\n\n-- 배열을 다시 여러 raw로 변환(explode) ----------\n\nSELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\n\n\n\n\n-- 함수 조회 ----------\n\nSHOW FUNCTIONS\n\n\n-- 시스템 함수 조회 ----------\n\nSHOW SYSTEM FUNCTIONS\n\n\n\n-- s로 시작하는 함수 조회 ----------\n\nSHOW FUNCTIONS \"s*\";\n\n\n-- collect로 시작하는 함수 조회 ----------\n\nSHOW FUNCTIONS LIKE \"collect*\";\n\n\n-- 함수 정의 ----------\n\ndef power3(number:Double):Double=number*number*number\nspark.udf.register(\"poser3\",power3(_:Double):Double)\n\nSELECT count, power3(count) FROM flights\n\n\n-- COMMAND ----------\n\nSELECT dest_country_name FROM flights\nGROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n\n\n-- 서브쿼리 생성 방법 ----------\n\nSELECT * FROM flights\nWHERE origin_country_name IN (SELECT dest_country_name FROM flights\n      GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n\n\n-- 서브쿼리 생성 방법 ----------\n\nSELECT * FROM flights f1\nWHERE EXISTS (SELECT 1 FROM flights f2\n            WHERE f1.dest_country_name = f2.origin_country_name)\nAND EXISTS (SELECT 1 FROM flights f2\n            WHERE f2.dest_country_name = f1.origin_country_name)\n\n\n-- 비상호연관 스칼라 쿼리 (즉 기존에 없는 부가 컬럼 생성) ----------\n\nSELECT *, (SELECT max(count) FROM flights) AS maximum FROM flights\n\n\n-- SQL 환경 설정 ----------\n\nSET spark.sql.shuffle.partitions=20\n","user":"anonymous","dateUpdated":"2021-07-11T01:28:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538725457567_1601242056","id":"20181005-074417_181379409","dateCreated":"2018-10-05T07:44:17+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2846"}],"name":"Spark-The-Definitive-Guide-Sql/Structured_APIs-Chapter_10_Spark_SQL.sql","id":"2DSSM6HJV","noteParams":{},"noteForms":{},"angularObjects":{"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}